{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume($)</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>SMA_30</th>\n",
       "      <th>SMA_60</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_rolling_std_7</th>\n",
       "      <th>Volume_rolling_mean_7</th>\n",
       "      <th>Volume_rolling_std_7</th>\n",
       "      <th>Close_rolling_mean_30</th>\n",
       "      <th>Close_rolling_std_30</th>\n",
       "      <th>Volume_rolling_mean_30</th>\n",
       "      <th>Volume_rolling_std_30</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28994.009766</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>40730301359</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>22428.243750</td>\n",
       "      <td>19715.608773</td>\n",
       "      <td>...</td>\n",
       "      <td>1284.059118</td>\n",
       "      <td>4.970113e+10</td>\n",
       "      <td>8.115395e+09</td>\n",
       "      <td>22428.243750</td>\n",
       "      <td>3661.566866</td>\n",
       "      <td>3.886562e+10</td>\n",
       "      <td>1.223869e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29376.455078</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>67865420765</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.093726</td>\n",
       "      <td>22850.972721</td>\n",
       "      <td>20018.558219</td>\n",
       "      <td>...</td>\n",
       "      <td>1936.633106</td>\n",
       "      <td>5.249153e+10</td>\n",
       "      <td>1.055716e+10</td>\n",
       "      <td>22850.972721</td>\n",
       "      <td>4019.854985</td>\n",
       "      <td>4.006346e+10</td>\n",
       "      <td>1.325301e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32129.408203</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>78665235202</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>23320.381315</td>\n",
       "      <td>20329.363493</td>\n",
       "      <td>...</td>\n",
       "      <td>2189.909798</td>\n",
       "      <td>5.423229e+10</td>\n",
       "      <td>1.376529e+10</td>\n",
       "      <td>23320.381315</td>\n",
       "      <td>4328.735995</td>\n",
       "      <td>4.155655e+10</td>\n",
       "      <td>1.494648e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open          High           Low         Close     Adj Close  \\\n",
       "0  28994.009766  29600.626953  28803.585938  29374.152344  29374.152344   \n",
       "1  29376.455078  33155.117188  29091.181641  32127.267578  32127.267578   \n",
       "2  32129.408203  34608.558594  32052.316406  32782.023438  32782.023438   \n",
       "\n",
       "     Volume($) Symbol  Daily Return        SMA_30        SMA_60  ...  \\\n",
       "0  40730301359    BTC      0.012842  22428.243750  19715.608773  ...   \n",
       "1  67865420765    BTC      0.093726  22850.972721  20018.558219  ...   \n",
       "2  78665235202    BTC      0.020380  23320.381315  20329.363493  ...   \n",
       "\n",
       "   Close_rolling_std_7  Volume_rolling_mean_7  Volume_rolling_std_7  \\\n",
       "0          1284.059118           4.970113e+10          8.115395e+09   \n",
       "1          1936.633106           5.249153e+10          1.055716e+10   \n",
       "2          2189.909798           5.423229e+10          1.376529e+10   \n",
       "\n",
       "   Close_rolling_mean_30  Close_rolling_std_30  Volume_rolling_mean_30  \\\n",
       "0           22428.243750           3661.566866            3.886562e+10   \n",
       "1           22850.972721           4019.854985            4.006346e+10   \n",
       "2           23320.381315           4328.735995            4.155655e+10   \n",
       "\n",
       "   Volume_rolling_std_30  Year  Month  Day  \n",
       "0           1.223869e+10  2021      1    1  \n",
       "1           1.325301e+10  2021      1    2  \n",
       "2           1.494648e+10  2021      1    3  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/df_ml.csv', sep=\",\")\n",
    "#df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "#df.drop(index=1, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allowed_cryptos = ['BTC', 'ETH', 'USDT', 'BNB', 'SOL', 'XRP', 'ADA', 'AVAX', 'DOGE']\n",
    "# Filter the DataFrame to include only the rows with symbols in the allowed list\n",
    "#df = df[df['Symbol'].isin(allowed_cryptos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Symbol','Close', 'Close_lag_1', 'Low','Midpoint','High','Open','Close_lag_3']] #\n",
    "#df = df[['Close','Symbol','Close_lag_7','EMA_90', '90_day_MA', 'Close_rolling_mean_30','EMA_60','EMA_26','SMA_30']]\n",
    "#df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "28             Close_lag_7        1\n",
    "12                  EMA_90        1\n",
    "23               90_day_MA        1\n",
    "34   Close_rolling_mean_30        1\n",
    "11                  EMA_60        2\n",
    "15                  EMA_26        3\n",
    "7                   SMA_30        4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Low</th>\n",
       "      <th>Midpoint</th>\n",
       "      <th>High</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTC</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29001.720703</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29202.106445</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28994.009766</td>\n",
       "      <td>27362.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTC</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>31123.149414</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29376.455078</td>\n",
       "      <td>28840.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTC</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>33330.437500</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32129.408203</td>\n",
       "      <td>29001.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BTC</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>28722.755859</td>\n",
       "      <td>31081.487305</td>\n",
       "      <td>33440.218750</td>\n",
       "      <td>32810.949219</td>\n",
       "      <td>29374.152344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BTC</td>\n",
       "      <td>33992.429688</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>30221.187500</td>\n",
       "      <td>32329.388672</td>\n",
       "      <td>34437.589844</td>\n",
       "      <td>31977.041016</td>\n",
       "      <td>32127.267578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16039</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.135291</td>\n",
       "      <td>2.101517</td>\n",
       "      <td>2.132578</td>\n",
       "      <td>2.163639</td>\n",
       "      <td>2.143799</td>\n",
       "      <td>2.045980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.156239</td>\n",
       "      <td>2.397342</td>\n",
       "      <td>2.638445</td>\n",
       "      <td>2.159645</td>\n",
       "      <td>2.092255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16041</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.424762</td>\n",
       "      <td>2.578523</td>\n",
       "      <td>2.732283</td>\n",
       "      <td>2.592313</td>\n",
       "      <td>2.135291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.418916</td>\n",
       "      <td>2.483391</td>\n",
       "      <td>2.547866</td>\n",
       "      <td>2.544140</td>\n",
       "      <td>2.160291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16043</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.344989</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.287904</td>\n",
       "      <td>2.356607</td>\n",
       "      <td>2.425310</td>\n",
       "      <td>2.425128</td>\n",
       "      <td>2.587086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16044 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol         Close   Close_lag_1           Low      Midpoint  \\\n",
       "0        BTC  29374.152344  29001.720703  28803.585938  29202.106445   \n",
       "1        BTC  32127.267578  29374.152344  29091.181641  31123.149414   \n",
       "2        BTC  32782.023438  32127.267578  32052.316406  33330.437500   \n",
       "3        BTC  31971.914062  32782.023438  28722.755859  31081.487305   \n",
       "4        BTC  33992.429688  31971.914062  30221.187500  32329.388672   \n",
       "...      ...           ...           ...           ...           ...   \n",
       "16039    TON      2.160291      2.135291      2.101517      2.132578   \n",
       "16040    TON      2.587086      2.160291      2.156239      2.397342   \n",
       "16041    TON      2.539670      2.587086      2.424762      2.578523   \n",
       "16042    TON      2.425865      2.539670      2.418916      2.483391   \n",
       "16043    TON      2.344989      2.425865      2.287904      2.356607   \n",
       "\n",
       "               High          Open   Close_lag_3  \n",
       "0      29600.626953  28994.009766  27362.437500  \n",
       "1      33155.117188  29376.455078  28840.953125  \n",
       "2      34608.558594  32129.408203  29001.720703  \n",
       "3      33440.218750  32810.949219  29374.152344  \n",
       "4      34437.589844  31977.041016  32127.267578  \n",
       "...             ...           ...           ...  \n",
       "16039      2.163639      2.143799      2.045980  \n",
       "16040      2.638445      2.159645      2.092255  \n",
       "16041      2.732283      2.592313      2.135291  \n",
       "16042      2.547866      2.544140      2.160291  \n",
       "16043      2.425310      2.425128      2.587086  \n",
       "\n",
       "[16044 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "artists_column = df['Symbol'].values.reshape(-1, 1)\n",
    "\n",
    "one_hot_encoded_artists = one_hot_encoder.fit_transform(artists_column)\n",
    "\n",
    "df['Symbol'] = np.argmax(one_hot_encoded_artists, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling and Spliting train,test,validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df.drop('Close', axis=1)  \n",
    "y = df['Close']\n",
    "\n",
    "# Split the dataset into training (70%), validation (15%), and test (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Low</th>\n",
       "      <th>Midpoint</th>\n",
       "      <th>High</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29001.720703</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29202.106445</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28994.009766</td>\n",
       "      <td>27362.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>31123.149414</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29376.455078</td>\n",
       "      <td>28840.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>33330.437500</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32129.408203</td>\n",
       "      <td>29001.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>28722.755859</td>\n",
       "      <td>31081.487305</td>\n",
       "      <td>33440.218750</td>\n",
       "      <td>32810.949219</td>\n",
       "      <td>29374.152344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>33992.429688</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>30221.187500</td>\n",
       "      <td>32329.388672</td>\n",
       "      <td>34437.589844</td>\n",
       "      <td>31977.041016</td>\n",
       "      <td>32127.267578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16039</th>\n",
       "      <td>10</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.135291</td>\n",
       "      <td>2.101517</td>\n",
       "      <td>2.132578</td>\n",
       "      <td>2.163639</td>\n",
       "      <td>2.143799</td>\n",
       "      <td>2.045980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040</th>\n",
       "      <td>10</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.156239</td>\n",
       "      <td>2.397342</td>\n",
       "      <td>2.638445</td>\n",
       "      <td>2.159645</td>\n",
       "      <td>2.092255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16041</th>\n",
       "      <td>10</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.424762</td>\n",
       "      <td>2.578523</td>\n",
       "      <td>2.732283</td>\n",
       "      <td>2.592313</td>\n",
       "      <td>2.135291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>10</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.418916</td>\n",
       "      <td>2.483391</td>\n",
       "      <td>2.547866</td>\n",
       "      <td>2.544140</td>\n",
       "      <td>2.160291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16043</th>\n",
       "      <td>10</td>\n",
       "      <td>2.344989</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.287904</td>\n",
       "      <td>2.356607</td>\n",
       "      <td>2.425310</td>\n",
       "      <td>2.425128</td>\n",
       "      <td>2.587086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16044 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol         Close   Close_lag_1           Low      Midpoint  \\\n",
       "0           3  29374.152344  29001.720703  28803.585938  29202.106445   \n",
       "1           3  32127.267578  29374.152344  29091.181641  31123.149414   \n",
       "2           3  32782.023438  32127.267578  32052.316406  33330.437500   \n",
       "3           3  31971.914062  32782.023438  28722.755859  31081.487305   \n",
       "4           3  33992.429688  31971.914062  30221.187500  32329.388672   \n",
       "...       ...           ...           ...           ...           ...   \n",
       "16039      10      2.160291      2.135291      2.101517      2.132578   \n",
       "16040      10      2.587086      2.160291      2.156239      2.397342   \n",
       "16041      10      2.539670      2.587086      2.424762      2.578523   \n",
       "16042      10      2.425865      2.539670      2.418916      2.483391   \n",
       "16043      10      2.344989      2.425865      2.287904      2.356607   \n",
       "\n",
       "               High          Open   Close_lag_3  \n",
       "0      29600.626953  28994.009766  27362.437500  \n",
       "1      33155.117188  29376.455078  28840.953125  \n",
       "2      34608.558594  32129.408203  29001.720703  \n",
       "3      33440.218750  32810.949219  29374.152344  \n",
       "4      34437.589844  31977.041016  32127.267578  \n",
       "...             ...           ...           ...  \n",
       "16039      2.163639      2.143799      2.045980  \n",
       "16040      2.638445      2.159645      2.092255  \n",
       "16041      2.732283      2.592313      2.135291  \n",
       "16042      2.547866      2.544140      2.160291  \n",
       "16043      2.425310      2.425128      2.587086  \n",
       "\n",
       "[16044 rows x 8 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df)  # Exclude 'Date' if it exists\n",
    "\n",
    "# Define a function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length, -1]  # Assuming the target (e.g., 'Close') is the last column\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 10  # Number of time steps to look back \n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 9.944701560016256e-06\n",
      "Epoch 10, Loss: 5.798764505016152e-06\n",
      "Epoch 20, Loss: 7.48903548810631e-05\n",
      "Epoch 30, Loss: 4.342392639955506e-05\n",
      "Epoch 40, Loss: 4.881552013102919e-05\n",
      "Epoch 50, Loss: 0.00012634934682864696\n",
      "Epoch 60, Loss: 2.7561285605770536e-05\n",
      "Epoch 70, Loss: 4.18828767578816e-06\n",
      "Epoch 80, Loss: 3.1684248824603856e-05\n",
      "Epoch 90, Loss: 0.02101113088428974\n",
      "Epoch 100, Loss: 9.269852853321936e-06\n",
      "Epoch 110, Loss: 1.4640721929026768e-05\n",
      "Epoch 120, Loss: 1.2070441698597278e-05\n",
      "Epoch 130, Loss: 1.6971753211691976e-06\n",
      "Epoch 140, Loss: 5.186968792258995e-06\n",
      "Epoch 150, Loss: 8.65877082105726e-05\n",
      "Epoch 160, Loss: 4.109285873710178e-05\n",
      "Epoch 170, Loss: 7.355161415034672e-06\n",
      "Epoch 180, Loss: 2.4566858769503597e-07\n",
      "Epoch 190, Loss: 2.788209030768485e-06\n"
     ]
    }
   ],
   "source": [
    "# Adjust hyperparameters\n",
    "hidden_dim = 85  # Number of LSTM units\n",
    "num_layers = 4  # Number of LSTM layers\n",
    "learning_rate = 0.001  # Learning rate for the optimizer\n",
    "batch_size = 64  # Batch size for training\n",
    "weight_decay = 1e-5  # L2 regularization term\n",
    "output_dim = 1\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "\n",
    "# Define the model\n",
    "model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "# Define the optimizer with weight decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Define a DataLoader for batch processing\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop with batch processing and gradient clipping\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 6.658186748609296e-07\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "model.eval()\n",
    "predicted = model(X_test)\n",
    "predicted = predicted.detach().numpy()\n",
    "actual = y_test.numpy()\n",
    "\n",
    "# You can use any metric for evaluation, here we use Mean Squared Error as an example\n",
    "test_loss = criterion(model(X_test), y_test)\n",
    "print(f'Test Loss: {test_loss.item()}')\n",
    "\n",
    "# Remember to invert the scaling for actual predictions before comparing them!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reshaped = np.zeros((len(predicted), scaled_data.shape[1]))  # Create a dummy array with the same width as 'scaled_data'\n",
    "predicted_reshaped[:, -1] = predicted.squeeze()  # Assuming the target feature is the last column\n",
    "\n",
    "actual_reshaped = np.zeros((len(actual), scaled_data.shape[1]))\n",
    "actual_reshaped[:, -1] = actual.squeeze()\n",
    "\n",
    "# Step 2: Apply the inverse transformation\n",
    "predicted_inverse = scaler.inverse_transform(predicted_reshaped)[:, -1]  # Select the target column after inversion\n",
    "actual_inverse = scaler.inverse_transform(actual_reshaped)[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 54.8468912008228\n",
      "Root Mean Squared Error (RMSE): 55.13298504196617\n",
      "Mean Absolute Percentage Error (MAPE): 5654.479431681335%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(actual_inverse, predicted_inverse)\n",
    "rmse = np.sqrt(mean_squared_error(actual_inverse, predicted_inverse))\n",
    "# MAPE function needs to handle division by zero, so we'll define it manually\n",
    "mape = np.mean(np.abs((actual_inverse - predicted_inverse) / actual_inverse)) * 100\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'actual_inverse' and 'predicted_inverse' are your actual and predicted values respectively\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(actual_inverse, label='Actual', color='blue')\n",
    "plt.plot(predicted_inverse, label='Predicted', color='red')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [916, 908]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m linear_reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mlinear_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m linear_reg\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1164\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [916, 908]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "linear_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = linear_reg.predict(X_test_scaled)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9998187610689385\n",
      "Mean Absolute Error (MAE): 30.318067887842968\n",
      "Root Mean Squared Error (RMSE): 141.21708306492204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Cross-Validated MSE: 21423.389740088758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_lr = cross_val_score(linear_reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_lr = -cv_scores_lr.mean()\n",
    "print(f\"Linear Regression Cross-Validated MSE: {mean_mse_lr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "Grid Search evaluates all the provided combinations of hyperparameters, which can be computationally expensive but thorough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'n_estimators': 120, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n",
      "Best score found:  195.77046215036302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [80, 100, 120, 140],\n",
    "    'max_depth': [20, 30, 40, None],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize the randomized search model\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n",
    "                                   n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1,\n",
    "                                   scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the randomized search model\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", np.sqrt(-random_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 275}\n",
      "Best score found:  38651.833918261735\n",
      "Test MSE: 34268.50814304979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 500),  # Number of trees in the forest\n",
    "    'max_depth': randint(10, 50),  # Maximum depth of the tree\n",
    "    'min_samples_split': randint(2, 11),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 11),  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,  # Number of parameter settings that are sampled\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,  # Controls the verbosity: the higher, the more messages\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Number of jobs to run in parallel (-1 means using all processors)\n",
    "    scoring='neg_mean_squared_error'  # Change according to your needs\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", -random_search.best_score_)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9996885615588167\n",
      "Mean Absolute Error (MAE): 41.22077809745639\n",
      "Root Mean Squared Error (RMSE): 185.11755222844155\n"
     ]
    }
   ],
   "source": [
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_independent_test_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have X_independent_test and y_independent_test prepared\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_independent \u001b[38;5;241m=\u001b[39m random_forest\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_independent_test_scaled\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m mse_independent \u001b[38;5;241m=\u001b[39m mean_squared_error(y_independent_test, y_pred_independent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_independent_test_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_independent_test and y_independent_test prepared\n",
    "y_pred_independent = random_forest.predict(X_independent_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_independent = mean_squared_error(y_independent_test, y_pred_independent)\n",
    "r2_independent = r2_score(y_independent_test, y_pred_independent)\n",
    "mae_independent = mean_absolute_error(y_independent_test, y_pred_independent)\n",
    "\n",
    "print(f\"Independent Test MSE: {mse_independent}\")\n",
    "print(f\"Independent Test R-squared: {r2_independent}\")\n",
    "print(f\"Independent Test MAE: {mae_independent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 504017.42934379855\n",
      "Average R-squared: -17.12640306626498\n",
      "Average MAE: 211.3903191462378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize model (assuming best parameters are already set)\n",
    "model = RandomForestRegressor(\n",
    "    max_depth=12, \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=2, \n",
    "    n_estimators=275,\n",
    "    random_state=42)\n",
    "\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "# Calculate average scores\n",
    "print(f\"Average MSE: {np.mean(mse_scores)}\")\n",
    "print(f\"Average R-squared: {np.mean(r2_scores)}\")\n",
    "print(f\"Average MAE: {np.mean(mae_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE with Best Parameters: 33160.30784583442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model with the best parameters from Grid Search\n",
    "random_forest = RandomForestRegressor(\n",
    "    n_estimators=120,  # Best number of trees\n",
    "    max_depth=30,  # Best maximum depth of trees\n",
    "    min_samples_leaf=1,  # Best minimum number of samples required at a leaf node\n",
    "    min_samples_split=2,  # Best minimum number of samples required to split an internal node\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = random_forest.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the test data\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE with Best Parameters: {mse_rf}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.999698633084885\n",
      "Mean Absolute Error (MAE): 40.328240554986756\n",
      "Root Mean Squared Error (RMSE): 182.09971951058688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred_rf)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross-Validated MSE: 96922514.69028388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_rf = cross_val_score(random_forest, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_rf = -cv_scores_rf.mean()\n",
    "print(f\"Random Forest Cross-Validated MSE: {mean_mse_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines (GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search\n",
    "Random Search samples a given number of candidates from a parameter space with a specified distribution. It's less comprehensive but much faster than Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'subsample': 0.6, 'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "Best score found:  39292.73854500158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter distribution to sample from\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'subsample': [0.6, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xg_reg = xgb.XGBRegressor()\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xg_reg, param_distributions=param_dist, n_iter=25, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", -random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBoost MSE: 32797.58750307243\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Adjusting the model with the best parameters found\n",
    "xg_reg_optimized = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.7,  # Updated from 0.3 to 0.7 based on the best parameters\n",
    "    learning_rate=0.1,     # Remains the same as before\n",
    "    max_depth=5,           # Remains the same as before\n",
    "    alpha=10,              # Remains the same as before\n",
    "    n_estimators=500,      # Updated from 10 to 500 based on the best parameters\n",
    "    subsample=0.8          # Added based on the best parameters\n",
    ")\n",
    "\n",
    "# Fit the model with the adjusted parameters\n",
    "xg_reg_optimized.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_optimized = xg_reg_optimized.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the adjusted parameters\n",
    "mse_xgb_optimized = mean_squared_error(y_test, y_pred_optimized)\n",
    "print(f\"Optimized XGBoost MSE: {mse_xgb_optimized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9997019295533995\n",
      "Mean Absolute Error (MAE): 39.37663597807381\n",
      "Root Mean Squared Error (RMSE): 181.10104224733888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred_optimized)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_optimized)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_optimized))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validated MSE: 98328661.26877618\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the model\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n",
    "                max_depth=5, alpha=10, n_estimators=10)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_xgb = cross_val_score(xg_reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_xgb = -cv_scores_xgb.mean()\n",
    "print(f\"XGBoost Cross-Validated MSE: {mean_mse_xgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [01:05<00:13,  1.18s/it]"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle your dataset (optional but recommended for cross-sectional data)\n",
    "#X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize LazyRegressor\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# Fit and compare models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the performance of each model\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/df_fs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

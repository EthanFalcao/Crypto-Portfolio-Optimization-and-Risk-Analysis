{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume($)</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>SMA_30</th>\n",
       "      <th>SMA_60</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_rolling_std_7</th>\n",
       "      <th>Volume_rolling_mean_7</th>\n",
       "      <th>Volume_rolling_std_7</th>\n",
       "      <th>Close_rolling_mean_30</th>\n",
       "      <th>Close_rolling_std_30</th>\n",
       "      <th>Volume_rolling_mean_30</th>\n",
       "      <th>Volume_rolling_std_30</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28994.009766</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>40730301359</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>22428.243750</td>\n",
       "      <td>19715.608773</td>\n",
       "      <td>...</td>\n",
       "      <td>1284.059118</td>\n",
       "      <td>4.970113e+10</td>\n",
       "      <td>8.115395e+09</td>\n",
       "      <td>22428.243750</td>\n",
       "      <td>3661.566866</td>\n",
       "      <td>3.886562e+10</td>\n",
       "      <td>1.223869e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29376.455078</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>67865420765</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.093726</td>\n",
       "      <td>22850.972721</td>\n",
       "      <td>20018.558219</td>\n",
       "      <td>...</td>\n",
       "      <td>1936.633106</td>\n",
       "      <td>5.249153e+10</td>\n",
       "      <td>1.055716e+10</td>\n",
       "      <td>22850.972721</td>\n",
       "      <td>4019.854985</td>\n",
       "      <td>4.006346e+10</td>\n",
       "      <td>1.325301e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32129.408203</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>78665235202</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>23320.381315</td>\n",
       "      <td>20329.363493</td>\n",
       "      <td>...</td>\n",
       "      <td>2189.909798</td>\n",
       "      <td>5.423229e+10</td>\n",
       "      <td>1.376529e+10</td>\n",
       "      <td>23320.381315</td>\n",
       "      <td>4328.735995</td>\n",
       "      <td>4.155655e+10</td>\n",
       "      <td>1.494648e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open          High           Low         Close     Adj Close  \\\n",
       "0  28994.009766  29600.626953  28803.585938  29374.152344  29374.152344   \n",
       "1  29376.455078  33155.117188  29091.181641  32127.267578  32127.267578   \n",
       "2  32129.408203  34608.558594  32052.316406  32782.023438  32782.023438   \n",
       "\n",
       "     Volume($) Symbol  Daily Return        SMA_30        SMA_60  ...  \\\n",
       "0  40730301359    BTC      0.012842  22428.243750  19715.608773  ...   \n",
       "1  67865420765    BTC      0.093726  22850.972721  20018.558219  ...   \n",
       "2  78665235202    BTC      0.020380  23320.381315  20329.363493  ...   \n",
       "\n",
       "   Close_rolling_std_7  Volume_rolling_mean_7  Volume_rolling_std_7  \\\n",
       "0          1284.059118           4.970113e+10          8.115395e+09   \n",
       "1          1936.633106           5.249153e+10          1.055716e+10   \n",
       "2          2189.909798           5.423229e+10          1.376529e+10   \n",
       "\n",
       "   Close_rolling_mean_30  Close_rolling_std_30  Volume_rolling_mean_30  \\\n",
       "0           22428.243750           3661.566866            3.886562e+10   \n",
       "1           22850.972721           4019.854985            4.006346e+10   \n",
       "2           23320.381315           4328.735995            4.155655e+10   \n",
       "\n",
       "   Volume_rolling_std_30  Year  Month  Day  \n",
       "0           1.223869e+10  2021      1    1  \n",
       "1           1.325301e+10  2021      1    2  \n",
       "2           1.494648e+10  2021      1    3  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/df_ml.csv', sep=\",\")\n",
    "#df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "#df.drop(index=1, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allowed_cryptos = ['BTC', 'ETH', 'USDT', 'BNB', 'SOL', 'XRP', 'ADA', 'AVAX', 'DOGE']\n",
    "# Filter the DataFrame to include only the rows with symbols in the allowed list\n",
    "#df = df[df['Symbol'].isin(allowed_cryptos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Symbol','Close', 'Close_lag_1', 'Low','Midpoint','High','Open','Close_lag_3']] #\n",
    "#df = df[['Close','Symbol','Close_lag_7','EMA_90', '90_day_MA', 'Close_rolling_mean_30','EMA_60','EMA_26','SMA_30']]\n",
    "#df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "28             Close_lag_7        1\n",
    "12                  EMA_90        1\n",
    "23               90_day_MA        1\n",
    "34   Close_rolling_mean_30        1\n",
    "11                  EMA_60        2\n",
    "15                  EMA_26        3\n",
    "7                   SMA_30        4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Low</th>\n",
       "      <th>Midpoint</th>\n",
       "      <th>High</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTC</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29001.720703</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29202.106445</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28994.009766</td>\n",
       "      <td>27362.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTC</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>31123.149414</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29376.455078</td>\n",
       "      <td>28840.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTC</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>33330.437500</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32129.408203</td>\n",
       "      <td>29001.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BTC</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>28722.755859</td>\n",
       "      <td>31081.487305</td>\n",
       "      <td>33440.218750</td>\n",
       "      <td>32810.949219</td>\n",
       "      <td>29374.152344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BTC</td>\n",
       "      <td>33992.429688</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>30221.187500</td>\n",
       "      <td>32329.388672</td>\n",
       "      <td>34437.589844</td>\n",
       "      <td>31977.041016</td>\n",
       "      <td>32127.267578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16039</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.135291</td>\n",
       "      <td>2.101517</td>\n",
       "      <td>2.132578</td>\n",
       "      <td>2.163639</td>\n",
       "      <td>2.143799</td>\n",
       "      <td>2.045980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.156239</td>\n",
       "      <td>2.397342</td>\n",
       "      <td>2.638445</td>\n",
       "      <td>2.159645</td>\n",
       "      <td>2.092255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16041</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.424762</td>\n",
       "      <td>2.578523</td>\n",
       "      <td>2.732283</td>\n",
       "      <td>2.592313</td>\n",
       "      <td>2.135291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.418916</td>\n",
       "      <td>2.483391</td>\n",
       "      <td>2.547866</td>\n",
       "      <td>2.544140</td>\n",
       "      <td>2.160291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16043</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.344989</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.287904</td>\n",
       "      <td>2.356607</td>\n",
       "      <td>2.425310</td>\n",
       "      <td>2.425128</td>\n",
       "      <td>2.587086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16044 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol         Close   Close_lag_1           Low      Midpoint  \\\n",
       "0        BTC  29374.152344  29001.720703  28803.585938  29202.106445   \n",
       "1        BTC  32127.267578  29374.152344  29091.181641  31123.149414   \n",
       "2        BTC  32782.023438  32127.267578  32052.316406  33330.437500   \n",
       "3        BTC  31971.914062  32782.023438  28722.755859  31081.487305   \n",
       "4        BTC  33992.429688  31971.914062  30221.187500  32329.388672   \n",
       "...      ...           ...           ...           ...           ...   \n",
       "16039    TON      2.160291      2.135291      2.101517      2.132578   \n",
       "16040    TON      2.587086      2.160291      2.156239      2.397342   \n",
       "16041    TON      2.539670      2.587086      2.424762      2.578523   \n",
       "16042    TON      2.425865      2.539670      2.418916      2.483391   \n",
       "16043    TON      2.344989      2.425865      2.287904      2.356607   \n",
       "\n",
       "               High          Open   Close_lag_3  \n",
       "0      29600.626953  28994.009766  27362.437500  \n",
       "1      33155.117188  29376.455078  28840.953125  \n",
       "2      34608.558594  32129.408203  29001.720703  \n",
       "3      33440.218750  32810.949219  29374.152344  \n",
       "4      34437.589844  31977.041016  32127.267578  \n",
       "...             ...           ...           ...  \n",
       "16039      2.163639      2.143799      2.045980  \n",
       "16040      2.638445      2.159645      2.092255  \n",
       "16041      2.732283      2.592313      2.135291  \n",
       "16042      2.547866      2.544140      2.160291  \n",
       "16043      2.425310      2.425128      2.587086  \n",
       "\n",
       "[16044 rows x 8 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "artists_column = df['Symbol'].values.reshape(-1, 1)\n",
    "\n",
    "one_hot_encoded_artists = one_hot_encoder.fit_transform(artists_column)\n",
    "\n",
    "df['Symbol'] = np.argmax(one_hot_encoded_artists, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling and Spliting train,test,validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df.drop('Close', axis=1)  \n",
    "y = df['Close']\n",
    "\n",
    "# Split the dataset into training (70%), validation (15%), and test (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Low</th>\n",
       "      <th>Midpoint</th>\n",
       "      <th>High</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29001.720703</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29202.106445</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28994.009766</td>\n",
       "      <td>27362.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>31123.149414</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29376.455078</td>\n",
       "      <td>28840.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>33330.437500</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32129.408203</td>\n",
       "      <td>29001.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>28722.755859</td>\n",
       "      <td>31081.487305</td>\n",
       "      <td>33440.218750</td>\n",
       "      <td>32810.949219</td>\n",
       "      <td>29374.152344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>33992.429688</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>30221.187500</td>\n",
       "      <td>32329.388672</td>\n",
       "      <td>34437.589844</td>\n",
       "      <td>31977.041016</td>\n",
       "      <td>32127.267578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16039</th>\n",
       "      <td>10</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.135291</td>\n",
       "      <td>2.101517</td>\n",
       "      <td>2.132578</td>\n",
       "      <td>2.163639</td>\n",
       "      <td>2.143799</td>\n",
       "      <td>2.045980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040</th>\n",
       "      <td>10</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.156239</td>\n",
       "      <td>2.397342</td>\n",
       "      <td>2.638445</td>\n",
       "      <td>2.159645</td>\n",
       "      <td>2.092255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16041</th>\n",
       "      <td>10</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.424762</td>\n",
       "      <td>2.578523</td>\n",
       "      <td>2.732283</td>\n",
       "      <td>2.592313</td>\n",
       "      <td>2.135291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>10</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.418916</td>\n",
       "      <td>2.483391</td>\n",
       "      <td>2.547866</td>\n",
       "      <td>2.544140</td>\n",
       "      <td>2.160291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16043</th>\n",
       "      <td>10</td>\n",
       "      <td>2.344989</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.287904</td>\n",
       "      <td>2.356607</td>\n",
       "      <td>2.425310</td>\n",
       "      <td>2.425128</td>\n",
       "      <td>2.587086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16044 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol         Close   Close_lag_1           Low      Midpoint  \\\n",
       "0           3  29374.152344  29001.720703  28803.585938  29202.106445   \n",
       "1           3  32127.267578  29374.152344  29091.181641  31123.149414   \n",
       "2           3  32782.023438  32127.267578  32052.316406  33330.437500   \n",
       "3           3  31971.914062  32782.023438  28722.755859  31081.487305   \n",
       "4           3  33992.429688  31971.914062  30221.187500  32329.388672   \n",
       "...       ...           ...           ...           ...           ...   \n",
       "16039      10      2.160291      2.135291      2.101517      2.132578   \n",
       "16040      10      2.587086      2.160291      2.156239      2.397342   \n",
       "16041      10      2.539670      2.587086      2.424762      2.578523   \n",
       "16042      10      2.425865      2.539670      2.418916      2.483391   \n",
       "16043      10      2.344989      2.425865      2.287904      2.356607   \n",
       "\n",
       "               High          Open   Close_lag_3  \n",
       "0      29600.626953  28994.009766  27362.437500  \n",
       "1      33155.117188  29376.455078  28840.953125  \n",
       "2      34608.558594  32129.408203  29001.720703  \n",
       "3      33440.218750  32810.949219  29374.152344  \n",
       "4      34437.589844  31977.041016  32127.267578  \n",
       "...             ...           ...           ...  \n",
       "16039      2.163639      2.143799      2.045980  \n",
       "16040      2.638445      2.159645      2.092255  \n",
       "16041      2.732283      2.592313      2.135291  \n",
       "16042      2.547866      2.544140      2.160291  \n",
       "16043      2.425310      2.425128      2.587086  \n",
       "\n",
       "[16044 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df)  # Exclude 'Date' if it exists\n",
    "\n",
    "# Define a function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length, -1]  # Assuming the target (e.g., 'Close') is the last column\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 10  # Number of time steps to look back \n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.02518504112958908\n",
      "Epoch 10, Loss: 0.008322748355567455\n",
      "Epoch 20, Loss: 0.0011781157227233052\n",
      "Epoch 30, Loss: 0.00038726095226593316\n",
      "Epoch 40, Loss: 0.00023773674911353737\n",
      "Epoch 50, Loss: 0.0001637124951230362\n",
      "Epoch 60, Loss: 0.00010985612607328221\n",
      "Epoch 70, Loss: 9.266912820748985e-05\n",
      "Epoch 80, Loss: 8.609973156126216e-05\n",
      "Epoch 90, Loss: 8.050792530411854e-05\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "\n",
    "# Model parameters\n",
    "input_dim = X_train.shape[2]\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.1589463560521835e-06\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "model.eval()\n",
    "predicted = model(X_test)\n",
    "predicted = predicted.detach().numpy()\n",
    "actual = y_test.numpy()\n",
    "\n",
    "# You can use any metric for evaluation, here we use Mean Squared Error as an example\n",
    "test_loss = criterion(model(X_test), y_test)\n",
    "print(f'Test Loss: {test_loss.item()}')\n",
    "\n",
    "# Remember to invert the scaling for actual predictions before comparing them!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'predicted' and 'actual' are your model's outputs and the true values, respectively,\n",
    "# and they are already converted to numpy arrays.\n",
    "# Let's also assume that 'Close' was the last column in your original dataset.\n",
    "\n",
    "# Step 1: Reshape your data (if necessary) to match the original data's shape before scaling\n",
    "# This might require adding dummy columns to match the number of features\n",
    "# Here, we're assuming the 'Close' price was a single feature among others\n",
    "predicted_reshaped = np.zeros((len(predicted), scaled_data.shape[1]))  # Create a dummy array with the same width as 'scaled_data'\n",
    "predicted_reshaped[:, -1] = predicted.squeeze()  # Assuming the target feature is the last column\n",
    "\n",
    "actual_reshaped = np.zeros((len(actual), scaled_data.shape[1]))\n",
    "actual_reshaped[:, -1] = actual.squeeze()\n",
    "\n",
    "# Step 2: Apply the inverse transformation\n",
    "predicted_inverse = scaler.inverse_transform(predicted_reshaped)[:, -1]  # Select the target column after inversion\n",
    "actual_inverse = scaler.inverse_transform(actual_reshaped)[:, -1]\n",
    "\n",
    "# Now 'predicted_inverse' and 'actual_inverse' are on the original scale and can be compared directly\n",
    "# For example, you can calculate RMSE or plot the values to assess the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 119.92940209491127\n",
      "Root Mean Squared Error (RMSE): 120.08938195850516\n",
      "Mean Absolute Percentage Error (MAPE): 12858.521812648345%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(actual_inverse, predicted_inverse)\n",
    "rmse = np.sqrt(mean_squared_error(actual_inverse, predicted_inverse))\n",
    "# MAPE function needs to handle division by zero, so we'll define it manually\n",
    "mape = np.mean(np.abs((actual_inverse - predicted_inverse) / actual_inverse)) * 100\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'actual_inverse' and 'predicted_inverse' are your actual and predicted values respectively\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(actual_inverse, label='Actual', color='blue')\n",
    "plt.plot(predicted_inverse, label='Predicted', color='red')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [916, 908]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m linear_reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mlinear_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m linear_reg\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1164\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [916, 908]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "linear_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = linear_reg.predict(X_test_scaled)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9998187610689385\n",
      "Mean Absolute Error (MAE): 30.318067887842968\n",
      "Root Mean Squared Error (RMSE): 141.21708306492204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Cross-Validated MSE: 21423.389740088758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_lr = cross_val_score(linear_reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_lr = -cv_scores_lr.mean()\n",
    "print(f\"Linear Regression Cross-Validated MSE: {mean_mse_lr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "Grid Search evaluates all the provided combinations of hyperparameters, which can be computationally expensive but thorough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'n_estimators': 120, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n",
      "Best score found:  195.77046215036302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [80, 100, 120, 140],\n",
    "    'max_depth': [20, 30, 40, None],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize the randomized search model\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n",
    "                                   n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1,\n",
    "                                   scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the randomized search model\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", np.sqrt(-random_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 275}\n",
      "Best score found:  38651.833918261735\n",
      "Test MSE: 34268.50814304979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 500),  # Number of trees in the forest\n",
    "    'max_depth': randint(10, 50),  # Maximum depth of the tree\n",
    "    'min_samples_split': randint(2, 11),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 11),  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,  # Number of parameter settings that are sampled\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,  # Controls the verbosity: the higher, the more messages\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Number of jobs to run in parallel (-1 means using all processors)\n",
    "    scoring='neg_mean_squared_error'  # Change according to your needs\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", -random_search.best_score_)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9996885615588167\n",
      "Mean Absolute Error (MAE): 41.22077809745639\n",
      "Root Mean Squared Error (RMSE): 185.11755222844155\n"
     ]
    }
   ],
   "source": [
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_independent_test_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have X_independent_test and y_independent_test prepared\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_independent \u001b[38;5;241m=\u001b[39m random_forest\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_independent_test_scaled\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m mse_independent \u001b[38;5;241m=\u001b[39m mean_squared_error(y_independent_test, y_pred_independent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_independent_test_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_independent_test and y_independent_test prepared\n",
    "y_pred_independent = random_forest.predict(X_independent_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_independent = mean_squared_error(y_independent_test, y_pred_independent)\n",
    "r2_independent = r2_score(y_independent_test, y_pred_independent)\n",
    "mae_independent = mean_absolute_error(y_independent_test, y_pred_independent)\n",
    "\n",
    "print(f\"Independent Test MSE: {mse_independent}\")\n",
    "print(f\"Independent Test R-squared: {r2_independent}\")\n",
    "print(f\"Independent Test MAE: {mae_independent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 504017.42934379855\n",
      "Average R-squared: -17.12640306626498\n",
      "Average MAE: 211.3903191462378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize model (assuming best parameters are already set)\n",
    "model = RandomForestRegressor(\n",
    "    max_depth=12, \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=2, \n",
    "    n_estimators=275,\n",
    "    random_state=42)\n",
    "\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "# Calculate average scores\n",
    "print(f\"Average MSE: {np.mean(mse_scores)}\")\n",
    "print(f\"Average R-squared: {np.mean(r2_scores)}\")\n",
    "print(f\"Average MAE: {np.mean(mae_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE with Best Parameters: 33160.30784583442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model with the best parameters from Grid Search\n",
    "random_forest = RandomForestRegressor(\n",
    "    n_estimators=120,  # Best number of trees\n",
    "    max_depth=30,  # Best maximum depth of trees\n",
    "    min_samples_leaf=1,  # Best minimum number of samples required at a leaf node\n",
    "    min_samples_split=2,  # Best minimum number of samples required to split an internal node\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = random_forest.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the test data\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE with Best Parameters: {mse_rf}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.999698633084885\n",
      "Mean Absolute Error (MAE): 40.328240554986756\n",
      "Root Mean Squared Error (RMSE): 182.09971951058688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred_rf)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross-Validated MSE: 96922514.69028388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_rf = cross_val_score(random_forest, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_rf = -cv_scores_rf.mean()\n",
    "print(f\"Random Forest Cross-Validated MSE: {mean_mse_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines (GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search\n",
    "Random Search samples a given number of candidates from a parameter space with a specified distribution. It's less comprehensive but much faster than Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'subsample': 0.6, 'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "Best score found:  39292.73854500158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter distribution to sample from\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'subsample': [0.6, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xg_reg = xgb.XGBRegressor()\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xg_reg, param_distributions=param_dist, n_iter=25, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", -random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBoost MSE: 32797.58750307243\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Adjusting the model with the best parameters found\n",
    "xg_reg_optimized = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.7,  # Updated from 0.3 to 0.7 based on the best parameters\n",
    "    learning_rate=0.1,     # Remains the same as before\n",
    "    max_depth=5,           # Remains the same as before\n",
    "    alpha=10,              # Remains the same as before\n",
    "    n_estimators=500,      # Updated from 10 to 500 based on the best parameters\n",
    "    subsample=0.8          # Added based on the best parameters\n",
    ")\n",
    "\n",
    "# Fit the model with the adjusted parameters\n",
    "xg_reg_optimized.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_optimized = xg_reg_optimized.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the adjusted parameters\n",
    "mse_xgb_optimized = mean_squared_error(y_test, y_pred_optimized)\n",
    "print(f\"Optimized XGBoost MSE: {mse_xgb_optimized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9997019295533995\n",
      "Mean Absolute Error (MAE): 39.37663597807381\n",
      "Root Mean Squared Error (RMSE): 181.10104224733888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred_optimized)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_optimized)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_optimized))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validated MSE: 98328661.26877618\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the model\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n",
    "                max_depth=5, alpha=10, n_estimators=10)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_xgb = cross_val_score(xg_reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_xgb = -cv_scores_xgb.mean()\n",
    "print(f\"XGBoost Cross-Validated MSE: {mean_mse_xgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [01:05<00:13,  1.18s/it]"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle your dataset (optional but recommended for cross-sectional data)\n",
    "#X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize LazyRegressor\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# Fit and compare models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the performance of each model\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/df_fs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume($)</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>SMA_30</th>\n",
       "      <th>SMA_60</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_rolling_std_7</th>\n",
       "      <th>Volume_rolling_mean_7</th>\n",
       "      <th>Volume_rolling_std_7</th>\n",
       "      <th>Close_rolling_mean_30</th>\n",
       "      <th>Close_rolling_std_30</th>\n",
       "      <th>Volume_rolling_mean_30</th>\n",
       "      <th>Volume_rolling_std_30</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28994.009766</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>40730301359</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>22428.243750</td>\n",
       "      <td>19715.608773</td>\n",
       "      <td>...</td>\n",
       "      <td>1284.059118</td>\n",
       "      <td>4.970113e+10</td>\n",
       "      <td>8.115395e+09</td>\n",
       "      <td>22428.243750</td>\n",
       "      <td>3661.566866</td>\n",
       "      <td>3.886562e+10</td>\n",
       "      <td>1.223869e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29376.455078</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>67865420765</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.093726</td>\n",
       "      <td>22850.972721</td>\n",
       "      <td>20018.558219</td>\n",
       "      <td>...</td>\n",
       "      <td>1936.633106</td>\n",
       "      <td>5.249153e+10</td>\n",
       "      <td>1.055716e+10</td>\n",
       "      <td>22850.972721</td>\n",
       "      <td>4019.854985</td>\n",
       "      <td>4.006346e+10</td>\n",
       "      <td>1.325301e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32129.408203</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>78665235202</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>23320.381315</td>\n",
       "      <td>20329.363493</td>\n",
       "      <td>...</td>\n",
       "      <td>2189.909798</td>\n",
       "      <td>5.423229e+10</td>\n",
       "      <td>1.376529e+10</td>\n",
       "      <td>23320.381315</td>\n",
       "      <td>4328.735995</td>\n",
       "      <td>4.155655e+10</td>\n",
       "      <td>1.494648e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open          High           Low         Close     Adj Close  \\\n",
       "0  28994.009766  29600.626953  28803.585938  29374.152344  29374.152344   \n",
       "1  29376.455078  33155.117188  29091.181641  32127.267578  32127.267578   \n",
       "2  32129.408203  34608.558594  32052.316406  32782.023438  32782.023438   \n",
       "\n",
       "     Volume($) Symbol  Daily Return        SMA_30        SMA_60  ...  \\\n",
       "0  40730301359    BTC      0.012842  22428.243750  19715.608773  ...   \n",
       "1  67865420765    BTC      0.093726  22850.972721  20018.558219  ...   \n",
       "2  78665235202    BTC      0.020380  23320.381315  20329.363493  ...   \n",
       "\n",
       "   Close_rolling_std_7  Volume_rolling_mean_7  Volume_rolling_std_7  \\\n",
       "0          1284.059118           4.970113e+10          8.115395e+09   \n",
       "1          1936.633106           5.249153e+10          1.055716e+10   \n",
       "2          2189.909798           5.423229e+10          1.376529e+10   \n",
       "\n",
       "   Close_rolling_mean_30  Close_rolling_std_30  Volume_rolling_mean_30  \\\n",
       "0           22428.243750           3661.566866            3.886562e+10   \n",
       "1           22850.972721           4019.854985            4.006346e+10   \n",
       "2           23320.381315           4328.735995            4.155655e+10   \n",
       "\n",
       "   Volume_rolling_std_30  Year  Month  Day  \n",
       "0           1.223869e+10  2021      1    1  \n",
       "1           1.325301e+10  2021      1    2  \n",
       "2           1.494648e+10  2021      1    3  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/df_ml.csv', sep=\",\")\n",
    "#df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "#df.drop(index=1, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        29001.720703\n",
       "1        29374.152344\n",
       "2        32127.267578\n",
       "3        32782.023438\n",
       "4        31971.914062\n",
       "             ...     \n",
       "16039        2.135291\n",
       "16040        2.160291\n",
       "16041        2.587086\n",
       "16042        2.539670\n",
       "16043        2.425865\n",
       "Name: Close_lag_1, Length: 16044, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Close_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        27362.437500\n",
       "1        28840.953125\n",
       "2        29001.720703\n",
       "3        29374.152344\n",
       "4        32127.267578\n",
       "             ...     \n",
       "16039        2.045980\n",
       "16040        2.092255\n",
       "16041        2.135291\n",
       "16042        2.160291\n",
       "16043        2.587086\n",
       "Name: Close_lag_3, Length: 16044, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Close_lag_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Close','Symbol', 'Close_lag_1', 'Low','Midpoint','High','Open','Close_lag_3']] #\n",
    "#df = df[['Close','Symbol','Close_lag_7','EMA_90', '90_day_MA', 'Close_rolling_mean_30','EMA_60','EMA_26','SMA_30']]\n",
    "#df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "28             Close_lag_7        1\n",
    "12                  EMA_90        1\n",
    "23               90_day_MA        1\n",
    "34   Close_rolling_mean_30        1\n",
    "11                  EMA_60        2\n",
    "15                  EMA_26        3\n",
    "7                   SMA_30        4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "\n",
    "artists_column = df['Symbol'].values.reshape(-1, 1)\n",
    "\n",
    "one_hot_encoded_artists = one_hot_encoder.fit_transform(artists_column)\n",
    "\n",
    "df['Symbol'] = np.argmax(one_hot_encoded_artists, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling and Spliting train,test,validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df.drop('Close', axis=1)  \n",
    "y = df['Close']\n",
    "\n",
    "# Split the dataset into training (70%), validation (15%), and test (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 19942.264549365093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "\n",
    "linear_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = linear_reg.predict(X_test_scaled)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9998187610689385\n",
      "Mean Absolute Error (MAE): 30.318067887842968\n",
      "Root Mean Squared Error (RMSE): 141.21708306492204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Cross-Validated MSE: 21423.389740088758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_lr = cross_val_score(linear_reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_lr = -cv_scores_lr.mean()\n",
    "print(f\"Linear Regression Cross-Validated MSE: {mean_mse_lr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "Grid Search evaluates all the provided combinations of hyperparameters, which can be computationally expensive but thorough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'n_estimators': 120, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n",
      "Best score found:  195.77046215036302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [80, 100, 120, 140],\n",
    "    'max_depth': [20, 30, 40, None],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize the randomized search model\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n",
    "                                   n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1,\n",
    "                                   scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the randomized search model\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", np.sqrt(-random_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 275}\n",
      "Best score found:  38651.833918261735\n",
      "Test MSE: 34268.50814304979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 500),  # Number of trees in the forest\n",
    "    'max_depth': randint(10, 50),  # Maximum depth of the tree\n",
    "    'min_samples_split': randint(2, 11),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 11),  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,  # Number of parameter settings that are sampled\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,  # Controls the verbosity: the higher, the more messages\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Number of jobs to run in parallel (-1 means using all processors)\n",
    "    scoring='neg_mean_squared_error'  # Change according to your needs\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", -random_search.best_score_)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9996885615588167\n",
      "Mean Absolute Error (MAE): 41.22077809745639\n",
      "Root Mean Squared Error (RMSE): 185.11755222844155\n"
     ]
    }
   ],
   "source": [
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_independent_test_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have X_independent_test and y_independent_test prepared\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_independent \u001b[38;5;241m=\u001b[39m random_forest\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_independent_test_scaled\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m mse_independent \u001b[38;5;241m=\u001b[39m mean_squared_error(y_independent_test, y_pred_independent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_independent_test_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_independent_test and y_independent_test prepared\n",
    "y_pred_independent = random_forest.predict(X_independent_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_independent = mean_squared_error(y_independent_test, y_pred_independent)\n",
    "r2_independent = r2_score(y_independent_test, y_pred_independent)\n",
    "mae_independent = mean_absolute_error(y_independent_test, y_pred_independent)\n",
    "\n",
    "print(f\"Independent Test MSE: {mse_independent}\")\n",
    "print(f\"Independent Test R-squared: {r2_independent}\")\n",
    "print(f\"Independent Test MAE: {mae_independent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 504017.42934379855\n",
      "Average R-squared: -17.12640306626498\n",
      "Average MAE: 211.3903191462378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize model (assuming best parameters are already set)\n",
    "model = RandomForestRegressor(\n",
    "    max_depth=12, \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=2, \n",
    "    n_estimators=275,\n",
    "    random_state=42)\n",
    "\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "# Calculate average scores\n",
    "print(f\"Average MSE: {np.mean(mse_scores)}\")\n",
    "print(f\"Average R-squared: {np.mean(r2_scores)}\")\n",
    "print(f\"Average MAE: {np.mean(mae_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE with Best Parameters: 33160.30784583442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model with the best parameters from Grid Search\n",
    "random_forest = RandomForestRegressor(\n",
    "    n_estimators=120,  # Best number of trees\n",
    "    max_depth=30,  # Best maximum depth of trees\n",
    "    min_samples_leaf=1,  # Best minimum number of samples required at a leaf node\n",
    "    min_samples_split=2,  # Best minimum number of samples required to split an internal node\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = random_forest.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the test data\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE with Best Parameters: {mse_rf}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.999698633084885\n",
      "Mean Absolute Error (MAE): 40.328240554986756\n",
      "Root Mean Squared Error (RMSE): 182.09971951058688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred_rf)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross-Validated MSE: 96922514.69028388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_rf = cross_val_score(random_forest, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_rf = -cv_scores_rf.mean()\n",
    "print(f\"Random Forest Cross-Validated MSE: {mean_mse_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines (GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search\n",
    "Random Search samples a given number of candidates from a parameter space with a specified distribution. It's less comprehensive but much faster than Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'subsample': 0.6, 'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "Best score found:  39292.73854500158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter distribution to sample from\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'subsample': [0.6, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xg_reg = xgb.XGBRegressor()\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xg_reg, param_distributions=param_dist, n_iter=25, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", -random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBoost MSE: 32797.58750307243\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Adjusting the model with the best parameters found\n",
    "xg_reg_optimized = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.7,  # Updated from 0.3 to 0.7 based on the best parameters\n",
    "    learning_rate=0.1,     # Remains the same as before\n",
    "    max_depth=5,           # Remains the same as before\n",
    "    alpha=10,              # Remains the same as before\n",
    "    n_estimators=500,      # Updated from 10 to 500 based on the best parameters\n",
    "    subsample=0.8          # Added based on the best parameters\n",
    ")\n",
    "\n",
    "# Fit the model with the adjusted parameters\n",
    "xg_reg_optimized.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_optimized = xg_reg_optimized.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the adjusted parameters\n",
    "mse_xgb_optimized = mean_squared_error(y_test, y_pred_optimized)\n",
    "print(f\"Optimized XGBoost MSE: {mse_xgb_optimized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9997019295533995\n",
      "Mean Absolute Error (MAE): 39.37663597807381\n",
      "Root Mean Squared Error (RMSE): 181.10104224733888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred_optimized)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_optimized)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_optimized))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validated MSE: 98328661.26877618\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the model\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n",
    "                max_depth=5, alpha=10, n_estimators=10)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_xgb = cross_val_score(xg_reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_xgb = -cv_scores_xgb.mean()\n",
    "print(f\"XGBoost Cross-Validated MSE: {mean_mse_xgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [01:05<00:13,  1.18s/it]"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle your dataset (optional but recommended for cross-sectional data)\n",
    "#X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize LazyRegressor\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# Fit and compare models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the performance of each model\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/df_fs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

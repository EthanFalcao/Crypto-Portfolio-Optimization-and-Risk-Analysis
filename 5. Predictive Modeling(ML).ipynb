{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume($)</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>SMA_30</th>\n",
       "      <th>SMA_60</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_rolling_std_7</th>\n",
       "      <th>Volume_rolling_mean_7</th>\n",
       "      <th>Volume_rolling_std_7</th>\n",
       "      <th>Close_rolling_mean_30</th>\n",
       "      <th>Close_rolling_std_30</th>\n",
       "      <th>Volume_rolling_mean_30</th>\n",
       "      <th>Volume_rolling_std_30</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28994.009766</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>40730301359</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>22428.243750</td>\n",
       "      <td>19715.608773</td>\n",
       "      <td>...</td>\n",
       "      <td>1284.059118</td>\n",
       "      <td>4.970113e+10</td>\n",
       "      <td>8.115395e+09</td>\n",
       "      <td>22428.243750</td>\n",
       "      <td>3661.566866</td>\n",
       "      <td>3.886562e+10</td>\n",
       "      <td>1.223869e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29376.455078</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>67865420765</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.093726</td>\n",
       "      <td>22850.972721</td>\n",
       "      <td>20018.558219</td>\n",
       "      <td>...</td>\n",
       "      <td>1936.633106</td>\n",
       "      <td>5.249153e+10</td>\n",
       "      <td>1.055716e+10</td>\n",
       "      <td>22850.972721</td>\n",
       "      <td>4019.854985</td>\n",
       "      <td>4.006346e+10</td>\n",
       "      <td>1.325301e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32129.408203</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>78665235202</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>23320.381315</td>\n",
       "      <td>20329.363493</td>\n",
       "      <td>...</td>\n",
       "      <td>2189.909798</td>\n",
       "      <td>5.423229e+10</td>\n",
       "      <td>1.376529e+10</td>\n",
       "      <td>23320.381315</td>\n",
       "      <td>4328.735995</td>\n",
       "      <td>4.155655e+10</td>\n",
       "      <td>1.494648e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open          High           Low         Close     Adj Close  \\\n",
       "0  28994.009766  29600.626953  28803.585938  29374.152344  29374.152344   \n",
       "1  29376.455078  33155.117188  29091.181641  32127.267578  32127.267578   \n",
       "2  32129.408203  34608.558594  32052.316406  32782.023438  32782.023438   \n",
       "\n",
       "     Volume($) Symbol  Daily Return        SMA_30        SMA_60  ...  \\\n",
       "0  40730301359    BTC      0.012842  22428.243750  19715.608773  ...   \n",
       "1  67865420765    BTC      0.093726  22850.972721  20018.558219  ...   \n",
       "2  78665235202    BTC      0.020380  23320.381315  20329.363493  ...   \n",
       "\n",
       "   Close_rolling_std_7  Volume_rolling_mean_7  Volume_rolling_std_7  \\\n",
       "0          1284.059118           4.970113e+10          8.115395e+09   \n",
       "1          1936.633106           5.249153e+10          1.055716e+10   \n",
       "2          2189.909798           5.423229e+10          1.376529e+10   \n",
       "\n",
       "   Close_rolling_mean_30  Close_rolling_std_30  Volume_rolling_mean_30  \\\n",
       "0           22428.243750           3661.566866            3.886562e+10   \n",
       "1           22850.972721           4019.854985            4.006346e+10   \n",
       "2           23320.381315           4328.735995            4.155655e+10   \n",
       "\n",
       "   Volume_rolling_std_30  Year  Month  Day  \n",
       "0           1.223869e+10  2021      1    1  \n",
       "1           1.325301e+10  2021      1    2  \n",
       "2           1.494648e+10  2021      1    3  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/df_ml.csv', sep=\",\")\n",
    "#df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "#df.drop(index=1, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Symbol','Close', 'Close_lag_1', 'Low','Midpoint','High','Open','Close_lag_3']] #\n",
    "#df = df[['Close','Symbol','Close_lag_7','EMA_90', '90_day_MA', 'Close_rolling_mean_30','EMA_60','EMA_26','SMA_30']]\n",
    "#df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "28             Close_lag_7        1\n",
    "12                  EMA_90        1\n",
    "23               90_day_MA        1\n",
    "34   Close_rolling_mean_30        1\n",
    "11                  EMA_60        2\n",
    "15                  EMA_26        3\n",
    "7                   SMA_30        4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Low</th>\n",
       "      <th>Midpoint</th>\n",
       "      <th>High</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTC</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29001.720703</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29202.106445</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28994.009766</td>\n",
       "      <td>27362.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTC</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>31123.149414</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29376.455078</td>\n",
       "      <td>28840.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTC</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>33330.437500</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32129.408203</td>\n",
       "      <td>29001.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BTC</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>28722.755859</td>\n",
       "      <td>31081.487305</td>\n",
       "      <td>33440.218750</td>\n",
       "      <td>32810.949219</td>\n",
       "      <td>29374.152344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BTC</td>\n",
       "      <td>33992.429688</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>30221.187500</td>\n",
       "      <td>32329.388672</td>\n",
       "      <td>34437.589844</td>\n",
       "      <td>31977.041016</td>\n",
       "      <td>32127.267578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16039</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.135291</td>\n",
       "      <td>2.101517</td>\n",
       "      <td>2.132578</td>\n",
       "      <td>2.163639</td>\n",
       "      <td>2.143799</td>\n",
       "      <td>2.045980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.156239</td>\n",
       "      <td>2.397342</td>\n",
       "      <td>2.638445</td>\n",
       "      <td>2.159645</td>\n",
       "      <td>2.092255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16041</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.424762</td>\n",
       "      <td>2.578523</td>\n",
       "      <td>2.732283</td>\n",
       "      <td>2.592313</td>\n",
       "      <td>2.135291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.418916</td>\n",
       "      <td>2.483391</td>\n",
       "      <td>2.547866</td>\n",
       "      <td>2.544140</td>\n",
       "      <td>2.160291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16043</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.344989</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.287904</td>\n",
       "      <td>2.356607</td>\n",
       "      <td>2.425310</td>\n",
       "      <td>2.425128</td>\n",
       "      <td>2.587086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16044 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol         Close   Close_lag_1           Low      Midpoint  \\\n",
       "0        BTC  29374.152344  29001.720703  28803.585938  29202.106445   \n",
       "1        BTC  32127.267578  29374.152344  29091.181641  31123.149414   \n",
       "2        BTC  32782.023438  32127.267578  32052.316406  33330.437500   \n",
       "3        BTC  31971.914062  32782.023438  28722.755859  31081.487305   \n",
       "4        BTC  33992.429688  31971.914062  30221.187500  32329.388672   \n",
       "...      ...           ...           ...           ...           ...   \n",
       "16039    TON      2.160291      2.135291      2.101517      2.132578   \n",
       "16040    TON      2.587086      2.160291      2.156239      2.397342   \n",
       "16041    TON      2.539670      2.587086      2.424762      2.578523   \n",
       "16042    TON      2.425865      2.539670      2.418916      2.483391   \n",
       "16043    TON      2.344989      2.425865      2.287904      2.356607   \n",
       "\n",
       "               High          Open   Close_lag_3  \n",
       "0      29600.626953  28994.009766  27362.437500  \n",
       "1      33155.117188  29376.455078  28840.953125  \n",
       "2      34608.558594  32129.408203  29001.720703  \n",
       "3      33440.218750  32810.949219  29374.152344  \n",
       "4      34437.589844  31977.041016  32127.267578  \n",
       "...             ...           ...           ...  \n",
       "16039      2.163639      2.143799      2.045980  \n",
       "16040      2.638445      2.159645      2.092255  \n",
       "16041      2.732283      2.592313      2.135291  \n",
       "16042      2.547866      2.544140      2.160291  \n",
       "16043      2.425310      2.425128      2.587086  \n",
       "\n",
       "[16044 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "\n",
    "artists_column = df['Symbol'].values.reshape(-1, 1)\n",
    "\n",
    "one_hot_encoded_artists = one_hot_encoder.fit_transform(artists_column)\n",
    "\n",
    "df['Symbol'] = np.argmax(one_hot_encoded_artists, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling and Spliting train,test,validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df.drop('Close', axis=1)  \n",
    "y = df['Close']\n",
    "\n",
    "# Split the dataset into training (70%), validation (15%), and test (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Ensure you're using a GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming lstm_test is your dataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "lstm_test_scaled = scaler.fit_transform(np.array(lstm_test).reshape(-1, 1))\n",
    "\n",
    "train_size = int(len(lstm_test_scaled) * 0.65)\n",
    "test_size = len(lstm_test_scaled) - train_size\n",
    "train_data, test_data = lstm_test_scaled[0:train_size, :], lstm_test_scaled[train_size:len(lstm_test_scaled), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Assuming the preprocessing and dataset creation steps have been completed\n",
    "# And you have X_train, Y_train, X_test, Y_test\n",
    "\n",
    "# Convert arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train).float().unsqueeze(-1)  # Add an extra dimension\n",
    "Y_train_tensor = torch.tensor(Y_train).float()\n",
    "X_test_tensor = torch.tensor(X_test).float().unsqueeze(-1)  # Add an extra dimension\n",
    "Y_test_tensor = torch.tensor(Y_test).float()\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "# Define your batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n",
    "        \n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :])  # Take the last output\n",
    "        return out\n",
    "\n",
    "# Initialize the model\n",
    "model = LSTMModel(input_dim=1, hidden_dim=50, num_layers=1, output_dim=1).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\ethan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([15])) that is different to the input size (torch.Size([15, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.02551858804629518\n",
      "Epoch 11, Loss: 0.025529913785057538\n",
      "Epoch 21, Loss: 0.025438469429787416\n",
      "Epoch 31, Loss: 0.025444579509736668\n",
      "Epoch 41, Loss: 0.02544003824572674\n",
      "Epoch 51, Loss: 0.02543543221703219\n",
      "Epoch 61, Loss: 0.025437909308575972\n",
      "Epoch 71, Loss: 0.025437324313670767\n",
      "Epoch 81, Loss: 0.025454029202684417\n",
      "Epoch 91, Loss: 0.0254535440960595\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        test_predictions.extend(outputs.cpu().detach().numpy())\n",
    "        test_targets.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "# Convert predictions and targets list to numpy arrays\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_targets = np.array(test_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your scaler was fit on the original data\n",
    "# You might need to reshape your data for the inverse transformation if it's required by your scaler\n",
    "test_predictions_inverse = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
    "test_targets_inverse = scaler.inverse_transform(test_targets.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0005631362437270582\n",
      "RMSE: 0.02373049185598685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(test_targets_inverse, test_predictions_inverse)\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, data_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.cpu().detach().numpy())\n",
    "            actuals.extend(labels.cpu().detach().numpy())\n",
    "    \n",
    "    return np.array(predictions), np.array(actuals)\n",
    "\n",
    "# Generate predictions and actuals for both training and testing datasets\n",
    "train_predictions, train_actuals = generate_predictions(model, train_loader)\n",
    "test_predictions, test_actuals = generate_predictions(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_inverse = scaler.inverse_transform(train_predictions.reshape(-1, 1))\n",
    "train_actuals_inverse = scaler.inverse_transform(train_actuals.reshape(-1, 1))\n",
    "test_predictions_inverse = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
    "test_actuals_inverse = scaler.inverse_transform(test_actuals.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Training data plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_actuals_inverse, label='Actual Values (Train)', color='blue')\n",
    "plt.plot(train_predictions_inverse, label='Predictions (Train)', color='red', alpha=0.7)\n",
    "plt.title('Training Data: Actual vs Prediction')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "# Test data plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_actuals_inverse, label='Actual Values (Test)', color='blue')\n",
    "plt.plot(test_predictions_inverse, label='Predictions (Test)', color='red', alpha=0.7)\n",
    "plt.title('Test Data: Actual vs Prediction')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n",
    "        \n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the X_train, Y_train, X_test, Y_test to Tensors\n",
    "X_train_tensor = torch.Tensor(X_train).unsqueeze(-1).to(device)\n",
    "Y_train_tensor = torch.Tensor(Y_train).unsqueeze(-1).to(device)\n",
    "X_test_tensor = torch.Tensor(X_test).unsqueeze(-1).to(device)\n",
    "Y_test_tensor = torch.Tensor(Y_test).unsqueeze(-1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 50\n",
    "num_layers = 3\n",
    "output_dim = 1\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 4.00 GiB of which 390.64 MiB is free. Of the allocated memory 2.20 GiB is allocated by PyTorch, and 1.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      4\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 5\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, Y_train_tensor)\n\u001b[0;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 15\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 15\u001b[0m out, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 4.00 GiB of which 390.64 MiB is free. Of the allocated memory 2.20 GiB is allocated by PyTorch, and 1.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, Y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch.keras.models import Sequential\n",
    "from pytorch.keras.layers import Dense\n",
    "from pytorch.keras.layers import LSTM\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128352, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "lstm_test = scaler.fit_transform(np.array(lstm_test).reshape(-1,1))\n",
    "lstm_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(lstm_test)*0.65)\n",
    "test_size = len(lstm_test) - train_size\n",
    "train_data,test_data = lstm_test[0:train_size,:],lstm_test[train_size:len(lstm_test),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step = 1):\n",
    "    dataX,dataY = [],[]\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "                   a = dataset[i:(i+time_step),0]\n",
    "                   dataX.append(a)\n",
    "                   dataY.append(dataset[i + time_step,0])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the create dataset function to split the data into \n",
    "# input output datasets with time step 100\n",
    "time_step = 100\n",
    "X_train,Y_train =  create_dataset(train_data,time_step)\n",
    "X_test,Y_test =  create_dataset(test_data,time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83327, 100)\n",
      "[[4.36112277e-05 4.27014282e-01 4.21600215e-01 ... 5.42470749e-01\n",
      "  4.93140658e-01 4.73685792e-01]\n",
      " [4.27014282e-01 4.21600215e-01 4.18719915e-01 ... 4.93140658e-01\n",
      "  4.73685792e-01 5.10139639e-01]\n",
      " [4.21600215e-01 4.18719915e-01 4.24513238e-01 ... 4.73685792e-01\n",
      "  5.10139639e-01 5.46593486e-01]\n",
      " ...\n",
      " [1.88264580e-06 1.99316389e-06 1.77784072e-06 ... 1.66136971e-06\n",
      "  1.58605313e-06 1.78922331e-06]\n",
      " [1.99316389e-06 1.77784072e-06 1.68534135e-06 ... 1.58605313e-06\n",
      "  1.78922331e-06 1.59907835e-04]\n",
      " [1.77784072e-06 1.68534135e-06 1.59907835e-04 ... 1.78922331e-06\n",
      "  1.59907835e-04 1.47509162e-06]]\n",
      "(44823, 100)\n",
      "(44823,)\n"
     ]
    }
   ],
   "source": [
    "# checking values\n",
    "print(X_train.shape)\n",
    "print(X_train)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50,return_sequences = True,input_shape = (X_train.shape[1],1)))\n",
    "model.add(LSTM(50,return_sequences = True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error',optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 50)           10400     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100, 50)           20200     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50851 (198.64 KB)\n",
      "Trainable params: 50851 (198.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1302/1302 [==============================] - 66133s 51s/step - loss: 0.0033 - val_loss: 1.5527e-05\n",
      "Epoch 2/100\n",
      "1302/1302 [==============================] - 246s 189ms/step - loss: 8.2190e-04 - val_loss: 1.5356e-06\n",
      "Epoch 3/100\n",
      "1302/1302 [==============================] - 255s 196ms/step - loss: 1.1732e-04 - val_loss: 2.6308e-05\n",
      "Epoch 4/100\n",
      "1302/1302 [==============================] - 256s 196ms/step - loss: 1.0391e-04 - val_loss: 9.1435e-08\n",
      "Epoch 5/100\n",
      "1302/1302 [==============================] - 253s 194ms/step - loss: 9.5678e-05 - val_loss: 7.4417e-07\n",
      "Epoch 6/100\n",
      "1302/1302 [==============================] - 267s 205ms/step - loss: 7.6695e-05 - val_loss: 5.1587e-06\n",
      "Epoch 7/100\n",
      " 886/1302 [===================>..........] - ETA: 1:10 - loss: 6.2022e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit(X_train,Y_train,validation_data = (X_test,Y_test),epochs = 100,batch_size = 64,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.1+cu118\n",
      "CUDA is available. GPU(s) detected:\n",
      "Number of GPUs available: 1\n",
      "GPU 0: GeForce GTX 1650\n",
      "PyTorch will use GPU: GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Print PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check for CUDA (GPU support)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU(s) detected:\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(\"PyTorch will use GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will run on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(X_train)\n",
    "test_predict = model. Predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to original form\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.sqrt(mean_squared_error(Y_train,train_predict)))\n",
    "print(math.sqrt(mean_squared_error(Y_test,test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 100\n",
    "\n",
    "trainPredictPlot = np.empty_like(df2)\n",
    "trainPredictPlot[:,:] = np.nan\n",
    "trainPredictPlot[look_back : len(train_predict)+look_back,:] = train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 19942.264549365093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "\n",
    "linear_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = linear_reg.predict(X_test_scaled)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9998187610689385\n",
      "Mean Absolute Error (MAE): 30.318067887842968\n",
      "Root Mean Squared Error (RMSE): 141.21708306492204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Cross-Validated MSE: 21423.389740088758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_lr = cross_val_score(linear_reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_lr = -cv_scores_lr.mean()\n",
    "print(f\"Linear Regression Cross-Validated MSE: {mean_mse_lr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "Grid Search evaluates all the provided combinations of hyperparameters, which can be computationally expensive but thorough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'n_estimators': 120, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n",
      "Best score found:  195.77046215036302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [80, 100, 120, 140],\n",
    "    'max_depth': [20, 30, 40, None],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize the randomized search model\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n",
    "                                   n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1,\n",
    "                                   scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the randomized search model\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", np.sqrt(-random_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 275}\n",
      "Best score found:  38651.833918261735\n",
      "Test MSE: 34268.50814304979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 500),  # Number of trees in the forest\n",
    "    'max_depth': randint(10, 50),  # Maximum depth of the tree\n",
    "    'min_samples_split': randint(2, 11),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 11),  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,  # Number of parameter settings that are sampled\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,  # Controls the verbosity: the higher, the more messages\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Number of jobs to run in parallel (-1 means using all processors)\n",
    "    scoring='neg_mean_squared_error'  # Change according to your needs\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", -random_search.best_score_)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9996885615588167\n",
      "Mean Absolute Error (MAE): 41.22077809745639\n",
      "Root Mean Squared Error (RMSE): 185.11755222844155\n"
     ]
    }
   ],
   "source": [
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_independent_test_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have X_independent_test and y_independent_test prepared\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_independent \u001b[38;5;241m=\u001b[39m random_forest\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_independent_test_scaled\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m mse_independent \u001b[38;5;241m=\u001b[39m mean_squared_error(y_independent_test, y_pred_independent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_independent_test_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_independent_test and y_independent_test prepared\n",
    "y_pred_independent = random_forest.predict(X_independent_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_independent = mean_squared_error(y_independent_test, y_pred_independent)\n",
    "r2_independent = r2_score(y_independent_test, y_pred_independent)\n",
    "mae_independent = mean_absolute_error(y_independent_test, y_pred_independent)\n",
    "\n",
    "print(f\"Independent Test MSE: {mse_independent}\")\n",
    "print(f\"Independent Test R-squared: {r2_independent}\")\n",
    "print(f\"Independent Test MAE: {mae_independent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 504017.42934379855\n",
      "Average R-squared: -17.12640306626498\n",
      "Average MAE: 211.3903191462378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize model (assuming best parameters are already set)\n",
    "model = RandomForestRegressor(\n",
    "    max_depth=12, \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=2, \n",
    "    n_estimators=275,\n",
    "    random_state=42)\n",
    "\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "# Calculate average scores\n",
    "print(f\"Average MSE: {np.mean(mse_scores)}\")\n",
    "print(f\"Average R-squared: {np.mean(r2_scores)}\")\n",
    "print(f\"Average MAE: {np.mean(mae_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE with Best Parameters: 33160.30784583442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model with the best parameters from Grid Search\n",
    "random_forest = RandomForestRegressor(\n",
    "    n_estimators=120,  # Best number of trees\n",
    "    max_depth=30,  # Best maximum depth of trees\n",
    "    min_samples_leaf=1,  # Best minimum number of samples required at a leaf node\n",
    "    min_samples_split=2,  # Best minimum number of samples required to split an internal node\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = random_forest.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the test data\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE with Best Parameters: {mse_rf}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.999698633084885\n",
      "Mean Absolute Error (MAE): 40.328240554986756\n",
      "Root Mean Squared Error (RMSE): 182.09971951058688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred_rf)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross-Validated MSE: 96922514.69028388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_rf = cross_val_score(random_forest, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_rf = -cv_scores_rf.mean()\n",
    "print(f\"Random Forest Cross-Validated MSE: {mean_mse_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines (GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search\n",
    "Random Search samples a given number of candidates from a parameter space with a specified distribution. It's less comprehensive but much faster than Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'subsample': 0.6, 'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "Best score found:  39292.73854500158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter distribution to sample from\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'subsample': [0.6, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xg_reg = xgb.XGBRegressor()\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xg_reg, param_distributions=param_dist, n_iter=25, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", -random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBoost MSE: 32797.58750307243\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Adjusting the model with the best parameters found\n",
    "xg_reg_optimized = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.7,  # Updated from 0.3 to 0.7 based on the best parameters\n",
    "    learning_rate=0.1,     # Remains the same as before\n",
    "    max_depth=5,           # Remains the same as before\n",
    "    alpha=10,              # Remains the same as before\n",
    "    n_estimators=500,      # Updated from 10 to 500 based on the best parameters\n",
    "    subsample=0.8          # Added based on the best parameters\n",
    ")\n",
    "\n",
    "# Fit the model with the adjusted parameters\n",
    "xg_reg_optimized.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_optimized = xg_reg_optimized.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the adjusted parameters\n",
    "mse_xgb_optimized = mean_squared_error(y_test, y_pred_optimized)\n",
    "print(f\"Optimized XGBoost MSE: {mse_xgb_optimized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9997019295533995\n",
      "Mean Absolute Error (MAE): 39.37663597807381\n",
      "Root Mean Squared Error (RMSE): 181.10104224733888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred_optimized)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_optimized)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_optimized))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validated MSE: 98328661.26877618\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the model\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n",
    "                max_depth=5, alpha=10, n_estimators=10)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_xgb = cross_val_score(xg_reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_xgb = -cv_scores_xgb.mean()\n",
    "print(f\"XGBoost Cross-Validated MSE: {mean_mse_xgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [01:05<00:13,  1.18s/it]"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle your dataset (optional but recommended for cross-sectional data)\n",
    "#X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize LazyRegressor\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# Fit and compare models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the performance of each model\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/df_fs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
